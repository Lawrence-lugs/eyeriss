{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "actBits = 8\n",
    "weightBits = 8\n",
    "outBits = 8\n",
    "nActs = 10\n",
    "nWeights = 3\n",
    "\n",
    "np.random.seed(0)\n",
    "a = np.random.randint(-2**(actBits-1),2**(actBits-1)-1,size=(nActs,nActs))\n",
    "w = np.random.randint(-2**(weightBits-1),2**(weightBits-1)-1,size=(nWeights,nWeights))\n",
    "o = convolve2d(a,w[::-1].T[::-1].T,mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "actBits = 3\n",
    "weightBits = 3\n",
    "nActs = 10\n",
    "nWeights = 3\n",
    "\n",
    "act_max_value = 2**(actBits-1) - 1\n",
    "weight_max_value = 2**(weightBits-1) - 1\n",
    "a = np.full((nActs, nActs), act_max_value)\n",
    "w = np.full((nWeights, nWeights), weight_max_value)\n",
    "o = convolve2d(a,w[::-1].T[::-1].T,mode='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation of Quantization per https://github.com/google/gemmlowp/blob/master/doc/quantization.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.9591, -1.8185, -0.4451, -1.2211,  1.2704, -0.7702, -0.5226,\n",
       "         -0.1785],\n",
       "        [-1.2139,  1.0255, -1.7152, -0.9167,  1.0068,  0.47  ,  2.4419,\n",
       "         -0.3409],\n",
       "        [ 1.6802,  1.4357,  0.6052,  0.9809, -1.3817, -0.3988,  0.3194,\n",
       "         -1.1724],\n",
       "        [-0.448 , -1.6343, -2.3635, -0.1885,  0.8053,  0.8301, -1.9913,\n",
       "          0.1775],\n",
       "        [ 0.0038,  0.3326,  0.1842, -0.1984, -1.5375, -0.7156,  0.5515,\n",
       "          0.7964],\n",
       "        [-0.3247, -1.0181, -0.8814,  1.096 ,  0.6712,  0.4481,  0.2406,\n",
       "         -0.2588],\n",
       "        [-1.8406, -0.204 , -0.1667, -0.7701, -1.6541,  1.2851,  0.5958,\n",
       "          1.6854],\n",
       "        [ 0.9127, -0.9696, -0.1113, -0.1411,  0.9557,  0.4367, -1.9155,\n",
       "          0.559 ]]),\n",
       " array([[-1.9591, -1.8186, -0.4451, -1.2211,  1.2704, -0.7702, -0.5226,\n",
       "         -0.1785],\n",
       "        [-1.2139,  1.0255, -1.7152, -0.9167,  1.0068,  0.47  ,  2.4419,\n",
       "         -0.3409],\n",
       "        [ 1.6802,  1.4358,  0.6052,  0.9809, -1.3817, -0.3988,  0.3194,\n",
       "         -1.1724],\n",
       "        [-0.448 , -1.6343, -2.3635, -0.1885,  0.8053,  0.8301, -1.9913,\n",
       "          0.1775],\n",
       "        [ 0.0038,  0.3326,  0.1842, -0.1984, -1.5375, -0.7156,  0.5515,\n",
       "          0.7964],\n",
       "        [-0.3247, -1.0181, -0.8814,  1.096 ,  0.6712,  0.4481,  0.2406,\n",
       "         -0.2588],\n",
       "        [-1.8406, -0.204 , -0.1667, -0.7701, -1.6541,  1.2851,  0.5958,\n",
       "          1.6854],\n",
       "        [ 0.9128, -0.9697, -0.1113, -0.1411,  0.9558,  0.4368, -1.9156,\n",
       "          0.559 ]]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiments on low-precision convolution\n",
    "\n",
    "from stim_lib.quant import *\n",
    "\n",
    "actBits = 8\n",
    "weightBits = 8\n",
    "outBits = 8\n",
    "nActs = 10\n",
    "nWeights = 3\n",
    "nOuts = nActs - nWeights + 1\n",
    "\n",
    "a = quantized_tensor((nActs,nActs),actBits) \n",
    "w = quantized_tensor((nWeights,nWeights),weightBits)\n",
    "o = scaling_quantized_convolution(a,w,outBits,internalPrecision=16)\n",
    "\n",
    "o.real_values - convolve_fake_quantized(a,w)\n",
    "# np.round(o.real_values,3) - np.round(convolve_reals(a,w),3)\n",
    "# np.allclose(o.real_values,convolve_reals(a,w),rtol=0.001)\n",
    "# Limit numpy print precision\n",
    "np.set_printoptions(precision=4)\n",
    "o.real_values, convolve_fake_quantized(a,w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real vs fixed point\t 0.010735642631708186 0.010735511779785156\n",
      "fixed point m0\t 1010111111100100\n",
      "shift\t-6\n",
      "m0\t0.68707275390625\n",
      "test_int\t -10044\n",
      "test_int x m0\t -452261232 -0b11010111101001111010101110000\n",
      "shifted by m0 fp\t -6901 -0b1101011110101\n",
      "then shifted by shift\t -107 -0b1101011\n",
      "saturating_clip\t\t -107\n",
      "m * test_int (ref)\t -107.82879459287702\n"
     ]
    }
   ],
   "source": [
    "# Experiments on the fixed point scaling\n",
    "outBits = 8\n",
    "inBits = 8\n",
    "fpBits = 16\n",
    "numSamples = 10\n",
    "\n",
    "out_scale = np.random.uniform(0,5) / (2**outBits)\n",
    "m0, shift = convert_scale_to_shift_and_m0(out_scale)\n",
    "print('real vs fixed point\\t',out_scale,m0 * 2**shift)\n",
    "m0bin = convert_to_fixed_point(m0,fpBits)\n",
    "print(f'fixed point m0\\t {m0bin}')\n",
    "print(f'shift\\t{shift}')\n",
    "print(f'm0\\t{m0}')\n",
    "\n",
    "m0int = int(m0bin,base=2)\n",
    "\n",
    "test_int = np.random.randint(-2**(inBits-1),2**(inBits-1)-1) * np.random.randint(-2**(inBits-1),2**(inBits-1)-1)\n",
    "print('test_int\\t',test_int)\n",
    "scaled = test_int*m0int\n",
    "scaled_clipped = scaled // (2**fpBits)\n",
    "scaled_clipped_shifted = int(scaled_clipped * 2**shift)\n",
    "print('test_int x m0\\t',scaled, bin(scaled))\n",
    "print('shifted by m0 fp\\t',scaled_clipped, bin(scaled_clipped))\n",
    "print('then shifted by shift\\t',scaled_clipped_shifted, bin(scaled_clipped_shifted))\n",
    "out = saturating_clip(scaled_clipped_shifted,outBits=outBits)\n",
    "print('saturating_clip\\t\\t',out)\n",
    "print('m * test_int (ref)\\t',test_int*out_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments on the fixed point scaling\n",
    "outBits = 8\n",
    "inBits = 8\n",
    "fpBits = 16\n",
    "numSamples = 10\n",
    "\n",
    "out_scale = np.random.uniform(0,5,10) / (2**outBits)\n",
    "m0, shift = np.vectorize(convert_scale_to_shift_and_m0)(out_scale)\n",
    "m0bin = np.vectorize(convert_to_fixed_point)(m0,fpBits)\n",
    "\n",
    "m0int = np.vectorize(int)(m0bin,base=2)\n",
    "\n",
    "test_int = np.random.randint(-2**(inBits-1),2**(inBits-1)-1,10) * np.random.randint(-2**(inBits-1),2**(inBits-1)-1,10)\n",
    "# print('test_int\\t',test_int)\n",
    "scaled = test_int*m0int\n",
    "scaled_clipped = scaled // (2**fpBits)\n",
    "scaled_clipped_shifted = np.vectorize(int)(scaled_clipped / 2**(-shift))\n",
    "# print('test_int x m0\\t',scaled, bin(scaled))\n",
    "# print('shifted by m0 fp\\t',scaled_clipped, bin(scaled_clipped))\n",
    "# print('then shifted by shift\\t',scaled_clipped_shifted, bin(scaled_clipped_shifted))\n",
    "out = np.vectorize(saturating_clip)(scaled_clipped_shifted,outBits=outBits)\n",
    "# print('saturating_clip\\t',out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x191900'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num = 3*16+2\n",
    "m0int = int(m0bin,base=2)\n",
    "scaled_int = m0int * test_num\n",
    "bin(scaled_int)\n",
    "hex(scaled_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12,  25, 111],\n",
       "       [-29, -78,  25],\n",
       "       [ 51, -67, 118]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.quantized_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ic_dec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

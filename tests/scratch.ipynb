{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "actBits = 8\n",
    "weightBits = 8\n",
    "outBits = 8\n",
    "nActs = 10\n",
    "nWeights = 3\n",
    "\n",
    "np.random.seed(0)\n",
    "a = np.random.randint(-2**(actBits-1),2**(actBits-1)-1,size=(nActs,nActs))\n",
    "w = np.random.randint(-2**(weightBits-1),2**(weightBits-1)-1,size=(nWeights,nWeights))\n",
    "o = convolve2d(a,w[::-1].T[::-1].T,mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "actBits = 3\n",
    "weightBits = 3\n",
    "nActs = 10\n",
    "nWeights = 3\n",
    "\n",
    "act_max_value = 2**(actBits-1) - 1\n",
    "weight_max_value = 2**(weightBits-1) - 1\n",
    "a = np.full((nActs, nActs), act_max_value)\n",
    "w = np.full((nWeights, nWeights), weight_max_value)\n",
    "o = convolve2d(a,w[::-1].T[::-1].T,mode='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation of Quantization per https://github.com/google/gemmlowp/blob/master/doc/quantization.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.0562,  1.3475, -1.0504, -1.0316,  0.8833,  1.675 , -1.4095,\n",
       "          0.4754],\n",
       "        [ 0.1941,  1.3914,  1.0818, -0.6051,  0.7486, -0.4316,  1.6213,\n",
       "         -1.7036],\n",
       "        [-2.5406,  0.8668,  1.2382, -1.5457, -2.5349, -0.2429,  0.166 ,\n",
       "          0.4121],\n",
       "        [ 1.5829, -2.0628, -0.9616,  3.2697, -0.4504, -0.3762, -0.0659,\n",
       "          0.2627],\n",
       "        [ 0.763 ,  2.1768, -0.136 , -1.2791,  1.535 ,  0.2247, -2.1347,\n",
       "          0.5068],\n",
       "        [-0.8132, -0.4034, -0.9699, -1.1228, -1.9253, -0.0043,  0.8805,\n",
       "          0.2682],\n",
       "        [-0.9916, -0.5115, -0.5937,  0.3508,  1.3887, -0.3928,  1.1233,\n",
       "         -1.04  ],\n",
       "        [-0.3788,  1.7169, -0.3493,  1.944 ,  0.7403, -0.6637, -0.1038,\n",
       "          0.1926]]),\n",
       " array([[-0.0562,  1.3475, -1.0504, -1.0316,  0.8833,  1.675 , -1.4095,\n",
       "          0.4754],\n",
       "        [ 0.1941,  1.3914,  1.0819, -0.6051,  0.7486, -0.4316,  1.6213,\n",
       "         -1.7037],\n",
       "        [-2.5406,  0.8668,  1.2382, -1.5457, -2.5349, -0.2429,  0.166 ,\n",
       "          0.4121],\n",
       "        [ 1.5829, -2.0628, -0.9617,  3.2698, -0.4504, -0.3762, -0.0659,\n",
       "          0.2627],\n",
       "        [ 0.763 ,  2.1768, -0.136 , -1.2791,  1.535 ,  0.2247, -2.1347,\n",
       "          0.5068],\n",
       "        [-0.8132, -0.4034, -0.9699, -1.1228, -1.9253, -0.0043,  0.8805,\n",
       "          0.2682],\n",
       "        [-0.9916, -0.5115, -0.5937,  0.3508,  1.3887, -0.3928,  1.1233,\n",
       "         -1.04  ],\n",
       "        [-0.3788,  1.7169, -0.3493,  1.9441,  0.7403, -0.6637, -0.1038,\n",
       "          0.1926]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiments on low-precision convolution\n",
    "\n",
    "from quant import *\n",
    "\n",
    "actBits = 8\n",
    "weightBits = 8\n",
    "outBits = 8\n",
    "nActs = 10\n",
    "nWeights = 3\n",
    "nOuts = nActs - nWeights + 1\n",
    "\n",
    "a = quantized_tensor((nActs,nActs),actBits) \n",
    "w = quantized_tensor((nWeights,nWeights),weightBits)\n",
    "o = scaling_quantized_convolution(a,w,outBits,internalPrecision=16)\n",
    "\n",
    "o.real_values - convolve_fake_quantized(a,w)\n",
    "# np.round(o.real_values,3) - np.round(convolve_reals(a,w),3)\n",
    "# np.allclose(o.real_values,convolve_reals(a,w),rtol=0.001)\n",
    "# Limit numpy print precision\n",
    "np.set_printoptions(precision=4)\n",
    "o.real_values, convolve_fake_quantized(a,w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00784313725490196 0.007843017578125\n",
      "fixed point m0: 1000000010000000\n",
      "-6.0\n",
      "0.501953125\n"
     ]
    }
   ],
   "source": [
    "# Experiments on the fixed point scaling\n",
    "outBits = 8\n",
    "out_scale = 2 / (2**outBits - 1)\n",
    "m = a.scale * w.scale / out_scale\n",
    "m0, shift = convert_scale_to_shift_and_m0(a.scale * w.scale / out_scale)\n",
    "print(m,m0 * 2**shift)\n",
    "print(f'fixed point m0: {convert_to_fixed_point(m0,16)}')\n",
    "print(shift)\n",
    "print(m0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ic_dec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

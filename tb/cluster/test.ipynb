{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate stimulus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PE cluster must be 14 PEs wide and 3 PEs high \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "actBits = 3\n",
    "weightBits = 3\n",
    "\n",
    "nActs = 16\n",
    "nWeights = 3\n",
    "nOuts = nActs - nWeights + 1\n",
    "\n",
    "a = np.random.randint(-2**(actBits-1),2**(actBits-1)-1,size=(nActs,nActs))\n",
    "w = np.random.randint(-2**(weightBits-1),2**(weightBits-1)-1,size=(nWeights,nWeights))\n",
    "o = convolve2d(a,w[::-1].T[::-1].T,mode='valid')\n",
    "\n",
    "print(f'PE cluster must be {nOuts} PEs wide and {nWeights} PEs high ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -2, -1,  2, -2,  0,  0,  1, -4, -1, -2, -3,  1,  1,  1,  1],\n",
       "       [-3, -1, -2, -1, -4,  1, -4,  0, -4, -3, -3, -1, -1, -4, -2, -2],\n",
       "       [-1, -1, -3, -4,  0, -4,  2, -4,  1,  0, -3,  2, -2, -4,  1, -3],\n",
       "       [-2, -4,  1,  1, -1,  1, -2,  0,  1,  2, -3, -4, -3,  1, -1,  1],\n",
       "       [ 1,  0, -4,  1, -3,  1, -4, -3, -2,  1, -4,  2,  1,  0,  1, -1],\n",
       "       [-3,  1,  1,  1, -3,  1,  2, -2, -3,  2, -2,  1,  0, -2, -3, -2],\n",
       "       [ 0,  1,  2,  0,  2, -1,  0, -2, -4, -3,  0,  1,  1,  1, -1,  2],\n",
       "       [ 1,  1,  2, -1,  0,  1,  1, -3,  0, -2, -3, -3,  2,  0,  2, -4],\n",
       "       [-2, -4, -3, -4,  2, -3, -4,  1,  2,  2,  2, -4,  2,  1,  2, -4],\n",
       "       [-3, -2,  0, -3,  2,  0,  0,  1, -4, -3,  2, -3,  1,  1, -2, -1],\n",
       "       [-4,  0, -4, -3,  1,  0, -4,  1,  2, -2, -3,  0, -3,  0,  2,  1],\n",
       "       [-4, -4,  1,  2,  0,  0,  2,  2, -3, -3,  0,  2, -3,  2, -3,  2],\n",
       "       [-4,  1,  0, -1, -3,  2, -4, -2, -3, -1,  0,  1, -1,  2, -3,  0],\n",
       "       [ 0, -4,  0, -2, -4, -3, -4, -1, -2,  1,  1, -1,  0,  2, -1, -2],\n",
       "       [ 1, -1, -3, -1, -1, -2, -1, -3, -2,  2,  0, -3, -2, -4, -1, -4],\n",
       "       [ 2,  2,  0,  0, -4, -1, -4,  2, -4,  0,  1, -2, -4, -2, -3, -4]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4,  1, -4],\n",
       "       [ 0, -2, -4],\n",
       "       [-4, -2, -1]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 25,  21,  52,  14,  28,  20,  32,  30,  40,  28,  17,  27,  24,\n",
       "         22],\n",
       "       [ 48,  41,  26,   9,  37,   4,  43,   2,  32,  13,  42,  60,  23,\n",
       "         29],\n",
       "       [ 19,  18,  27,  31,   8,  45,   4,  22,  26,  13,  53,  -2,  -3,\n",
       "         26],\n",
       "       [ 25,  10,   8,  -6,  35,   8,  17,   5,  34,   0,  18,   5,  20,\n",
       "          9],\n",
       "       [  2, -22,  29, -12,  13,  14,  45,  23,  51,  -5,   9,  -6,   3,\n",
       "         15],\n",
       "       [ -9, -18,  -5,  -8,   4,  11,  24,  31,  35,  -1,  19,   6,   2,\n",
       "          7],\n",
       "       [  2,  24,   4,  17, -13,  41,  32,  14,  15,  18,  -7,   0, -19,\n",
       "         -5],\n",
       "       [ 25,  35,  -5,  16,  11,  12, -15,  15,  18,  40,  -2,  15, -30,\n",
       "         31],\n",
       "       [ 40,  52,  19,  36,   5,   7,  35,   4, -17,  32,  -3,  14,   1,\n",
       "         17],\n",
       "       [ 49,  52, -17,   4,   6,  -6,  -2,   9,  39,  42,  -4,  11,   8,\n",
       "        -14],\n",
       "       [ 50,  -5,  10,  21,  16, -18,  40,  39,  22,   0,  31,  -9,  15,\n",
       "         -6],\n",
       "       [ 14,  31,  20,   9,  30,  31,  42,  18,  16,  -5,  14, -23,  31,\n",
       "        -17],\n",
       "       [ 26,  19,  46,  21,  61,  21,  48,  23,   9,  -3,  15,  -1,  35,\n",
       "         21],\n",
       "       [ -2,  26,  24,  35,  59,  36,  53,  -6,  16,  13,  13,  34,  41,\n",
       "         35]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare scan chains for multicast ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.],\n",
       "       [ 1.,  2.,  3.],\n",
       "       [ 2.,  3.,  4.],\n",
       "       [ 3.,  4.,  5.],\n",
       "       [ 4.,  5.,  6.],\n",
       "       [ 5.,  6.,  7.],\n",
       "       [ 6.,  7.,  8.],\n",
       "       [ 7.,  8.,  9.],\n",
       "       [ 8.,  9., 10.],\n",
       "       [ 9., 10., 11.],\n",
       "       [10., 11., 12.],\n",
       "       [11., 12., 13.],\n",
       "       [12., 13., 14.],\n",
       "       [13., 14., 15.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_acts = np.zeros((nOuts+1,nWeights))\n",
    "for x,idx in enumerate(ids_acts):\n",
    "    for y,id in enumerate(idx):\n",
    "        ids_acts[x][y] = x + y\n",
    "ids_acts[-1] = [0,0,0] # Only zeros for the Y-bus for now (you only need it for multichannel convolutions)\n",
    "ids_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_weights = np.zeros((nOuts+1,nWeights))\n",
    "for x,idx in enumerate(ids_weights):\n",
    "    ids_weights[x] = [i for i in range(nWeights)]\n",
    "ids_weights[-1] = [0,0,0] # Only zeros for the Y-bus for now (you only need it for multichannel convolutions)\n",
    "ids_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_order_acts = []\n",
    "for i in range(nActs):\n",
    "    tag_order_acts.append([0,i])\n",
    "tag_order_acts = np.array(tag_order_acts)\n",
    "\n",
    "tag_order_weights = []\n",
    "for i in range(nWeights):\n",
    "    tag_order_weights.append([0,i])\n",
    "tag_order_weights = np.array(tag_order_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save stimulus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/lquizon/lawrence-workspace/eyeriss/tb/cluster'\n",
    "np.savetxt(path + '/a.txt',a,'%i')\n",
    "np.savetxt(path + '/w.txt',w,'%i')\n",
    "np.savetxt(path + '/o.txt',o,'%i')\n",
    "np.savetxt(path + '/ids_acts.txt',ids_acts,'%i')\n",
    "np.savetxt(path + '/ids_weights.txt',ids_weights,'%i')\n",
    "np.savetxt(path + '/tag_order_acts.txt',tag_order_acts,'%i')\n",
    "np.savetxt(path + '/tag_order_weights.txt',tag_order_weights,'%i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a look at existing stimulus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "path = '.'\n",
    "a = np.loadtxt(path + '/a.txt')\n",
    "w = np.loadtxt(path + '/w.txt')\n",
    "o= np.loadtxt(path+'/o.txt')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row-stationary Forensics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  6.,  -1.,  14., -10.,   8.,  -4.,  17.,  -4.,  23.,  14.,\n",
       "           1.,   9.,  -7.,  -7.],\n",
       "        [ 10.,   8.,  18.,   4.,  14.,   8.,  16.,  20.,  18.,  10.,\n",
       "           6.,  18.,  16.,  12.],\n",
       "        [  9.,  14.,  20.,  20.,   6.,  16.,  -1.,  14.,  -1.,   4.,\n",
       "          10.,   0.,  15.,  17.]],\n",
       "\n",
       "       [[ 19.,   6.,  23.,  -4.,  33.,  -8.,  32.,   8.,  25.,  13.,\n",
       "          15.,  19.,   8.,  22.],\n",
       "        [ 14.,  22.,   8.,  16.,   0.,  12.,   4.,  -2.,  12.,  -2.,\n",
       "           4.,  20.,   4.,  10.],\n",
       "        [ 15.,  13.,  -5.,  -3.,   4.,   0.,   7.,  -4.,  -5.,   2.,\n",
       "          23.,  21.,  11.,  -3.]],\n",
       "\n",
       "       [[ 15.,  17.,   8.,  32., -12.,  34., -16.,  17.,   8., -11.,\n",
       "          22.,   6.,   0.,  29.],\n",
       "        [  4.,  -6.,   2.,  -2.,   6.,   4.,  -4., -10.,   8.,  22.,\n",
       "          20.,   2.,   2.,  -2.],\n",
       "        [  0.,   7.,  17.,   1.,  14.,   7.,  24.,  15.,  10.,   2.,\n",
       "          11., -10.,  -5.,  -1.]]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osize = nActsX-nWeights+1\n",
    "sequence_array = [[\n",
    "    (0, 0), # 0,0\n",
    "    (1, 1), # \n",
    "    (2, 2),\n",
    "    ],[\n",
    "    (0, 1),\n",
    "    (1, 2),\n",
    "    (2, 3),\n",
    "    ],[\n",
    "    (0, 2),\n",
    "    (1, 3),\n",
    "    (2, 4)\n",
    "    ]\n",
    "]\n",
    "ps = []\n",
    "psr = []\n",
    "\n",
    "for sequence in sequence_array:\n",
    "    psr = []\n",
    "    for wrow,arow in sequence:\n",
    "        psr.append(np.convolve(a[arow],w[wrow][::-1],'valid'))   \n",
    "    ps.append(psr)\n",
    "\n",
    "np.array(ps)\n",
    "\n",
    "# Expected PE partial sums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  6.,  -1.,  14., -10.,   8.,  -4.,  17.,  -4.,  23.,  14.,\n",
       "           1.,   9.,  -7.,  -7.],\n",
       "        [ 16.,   7.,  32.,  -6.,  22.,   4.,  33.,  16.,  41.,  24.,\n",
       "           7.,  27.,   9.,   5.],\n",
       "        [ 25.,  21.,  52.,  14.,  28.,  20.,  32.,  30.,  40.,  28.,\n",
       "          17.,  27.,  24.,  22.]],\n",
       "\n",
       "       [[ 19.,   6.,  23.,  -4.,  33.,  -8.,  32.,   8.,  25.,  13.,\n",
       "          15.,  19.,   8.,  22.],\n",
       "        [ 33.,  28.,  31.,  12.,  33.,   4.,  36.,   6.,  37.,  11.,\n",
       "          19.,  39.,  12.,  32.],\n",
       "        [ 48.,  41.,  26.,   9.,  37.,   4.,  43.,   2.,  32.,  13.,\n",
       "          42.,  60.,  23.,  29.]],\n",
       "\n",
       "       [[ 15.,  17.,   8.,  32., -12.,  34., -16.,  17.,   8., -11.,\n",
       "          22.,   6.,   0.,  29.],\n",
       "        [ 19.,  11.,  10.,  30.,  -6.,  38., -20.,   7.,  16.,  11.,\n",
       "          42.,   8.,   2.,  27.],\n",
       "        [ 19.,  18.,  27.,  31.,   8.,  45.,   4.,  22.,  26.,  13.,\n",
       "          53.,  -2.,  -3.,  26.]]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ress = []\n",
    "for psr in ps:\n",
    "    res = psr.copy()\n",
    "    for i in range(1,len(res)):\n",
    "        res[i] += res[i-1]\n",
    "    ress.append(res)\n",
    "np.array(ress)\n",
    "\n",
    "# Expected partial sum outputs in systolic passing:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ic_dec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
